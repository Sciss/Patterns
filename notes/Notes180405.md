# Serialization

So the first problem to think of is that `Pat[A]` _assumes_ it can be serialised 
and deserialised, using pattern matching with primitive types, basic containers
(Set, Map, Seq), products (case classes) and patterns themselves.

For `Stream[S, A]`, we could thus use the same concept, although the question is
how fast that is for primitive types, e.g. `Var[A]` instead of `Var[Int]`. Plus,
it means we do inevitably have to cast to `A`...

The only alternative would be to force the `Serializer` instances on `Pat` itself :-/
It's an interesting problem because in terms of lucre, we haven't much designed
a scheme yet for type-parametrised `Obj`. Let's look at a more complex example,
such as `BinaryOp`:

```
case class BinaryOp[A1, A2, A3, A](op: BinaryOp.Op[A3, A], a: Pat[A1], b: Pat[A2])
                                  (implicit w: Widen2[A1, A2, A3])
  extends Pattern[A]
```

Obviously, using the top-down approach to serializers, there is no way we can
get a general `Serializer[S#Tx, S#Acc, Pat[A]]`, as here we would need to obtain
an opaque peer serializer for `Pat[A1]` etc. Writers would be more easy. We could
assume that

```
trait Pat[A] {
  def writer: Writer[A]
}
```

and thus serialising is straight forward. Could the following help?

```
trait Pat[A] {
  def serializer[S <: Base[S]]: Serializer[S#Tx, S#Acc, A]
}
```

? In a way yes, if we define something like `PatSer <: Serializer with Aux`,
so we have a global knowledge (through `Aux`) of anything that could appear
within a pattern element type. Now an `Aux` is nothing but an identifier, so
when deserialising `Aux`, we have to cast the result (that's what happens in
the current `Pat` serializer). In order to support "composed aux instances",
we need to add `Writable` to `Aux` and use that instead of putting simply the
identifier in serialisation. Basically, what we do is have an approach not unlike
`Elem.Factory`. The difference and perhaps simplification here is that, since
patterns are immutable, their elements are supposed to be immutable, too.
So pattern elements are more restricted than `stm.Elem`, they can't have a
system type parameter, etc. Indeed, we should not need a system type parameter
in the `serializer` method, e.g.

```
trait Pat[A] {
  def serializer: PatSer[A]
}
```

Or just:

```
trait Pat[A] {
  def serializer: ImmutableSerializer[Pat[A]]
}
```

And thus the whole thing disintegrates, and there is no reason why this should
be a method _within_ `Pat`, it must naturally be a global serializer.
Let's go back:

```
case class BinaryOp[A1, A2, A3, A](op: BinaryOp.Op[A3, A], a: Pat[A1], b: Pat[A2])
                                  (implicit w: Widen2[A1, A2, A3])
  extends Pattern[A]
```

Again, the `Writable` would be trivial if any element type is constrained by
coming with a `Writer[A]`.

```
trait BinaryOp[A1, A2, A3, A] {
  def write(out: DataOutput): Unit = {
    op.write(out)
    a .write(out)
    b .write(out)
    writeAuxes(out)
  }
```

Observe how we don't need any additional type class parameter for `BinaryOp`. This
would be true for any pattern whose arguments are either other patterns or non-parametrised
primitives. Which are the patterns that do _not_ fall into this category?

- `Constant`
- `PatSeq`
- (`It` -- I don't think so)
- `Updated` -- should `elem` be `Pat[A]` instead?

So while `Updated` is perhaps a bit pathological and might be changed, basically these are the two
patterns that would need to constrain `A`: `Constant` and `PatSeq`, along with some auxiliary constructors
such as `Pat.fold`.

Thus, if we go back to the Serial library, and introduce a sub-type of `ImmutableSerializer`, e.g.
`KnownSerializer`, with a factory for additional registrations, So we want to load this onto the Serial
library, we should probably already include the primitives and containers from `ImmutableSerializer` in
`KnownSerializer` and have a factory registry pre-initialised. That is not ideal.

Or wait - it also means that the serialisation needs a header, so we won't be able to use the 'identified'
serialisers, anyway. Thus, we could just set up a separate structure.

Recall `Elem` deserialisation:

```
val typeId  = in.readInt()
val tpe     = getType(typeId)
tpe.readIdentifiedObj(in, access)

@inline
def getType(id: Int): Elem.Type = map.getOrElse(id, sys.error(s"Unknown element type $id"))
```

We could preface this with a `@switch` based table for primitives (see `readElem`) etc. and probably get the 
same performance as the current `Pat` deserialiser? In any case, we would have to have a result type cast.

---------------

Since it does not look like we can do any better, performance-wise, than `readElem` in `Pattern.serializer`, we
should just go ahead and use this dynamic approach, forget (for now) any additional constraints put on `A` in
`Pat[A]`, and therefore put the machinery only into `Stream`.

__Or:__ We could actually add constraints to `Constant` and `PatSeq`, they would simply be a `Serializable[A]`
which is pure evidence, so could be a cheap `Aux` in the end w.r.t serialization, and for `new` operation, would
be satisfied by anything that is eaten by `readElem` (primitives plus `Product`).
